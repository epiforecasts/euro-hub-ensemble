% Options for packages loaded elsewhere
%DIF LATEXDIFF DIFFERENCE FILE


\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Predictive performance of multi-model ensemble forecasts of COVID-19 across European nations},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}
\usepackage{setspace}\doublespacing
\usepackage{colortbl}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi

\title{Predictive performance of multi-model ensemble forecasts of COVID-19 across European nations}
\author{}
\date{\vspace{-2.5em}}
%DIF PREAMBLE EXTENSION ADDED BY LATEXDIFF
%DIF UNDERLINE PREAMBLE %DIF PREAMBLE
\RequirePackage[normalem]{ulem} %DIF PREAMBLE
\RequirePackage{color}\definecolor{RED}{rgb}{1,0,0}\definecolor{BLUE}{rgb}{0,0,1} %DIF PREAMBLE
\providecommand{\DIFaddtex}[1]{{\protect\color{blue}\uwave{#1}}} %DIF PREAMBLE
\providecommand{\DIFdeltex}[1]{{\protect\color{red}\sout{#1}}}                      %DIF PREAMBLE
%DIF SAFE PREAMBLE %DIF PREAMBLE
\providecommand{\DIFaddbegin}{} %DIF PREAMBLE
\providecommand{\DIFaddend}{} %DIF PREAMBLE
\providecommand{\DIFdelbegin}{} %DIF PREAMBLE
\providecommand{\DIFdelend}{} %DIF PREAMBLE
%DIF FLOATSAFE PREAMBLE %DIF PREAMBLE
\providecommand{\DIFaddFL}[1]{\DIFadd{#1}} %DIF PREAMBLE
\providecommand{\DIFdelFL}[1]{\DIFdel{#1}} %DIF PREAMBLE
\providecommand{\DIFaddbeginFL}{} %DIF PREAMBLE
\providecommand{\DIFaddendFL}{} %DIF PREAMBLE
\providecommand{\DIFdelbeginFL}{} %DIF PREAMBLE
\providecommand{\DIFdelendFL}{} %DIF PREAMBLE
%DIF HYPERREF PREAMBLE %DIF PREAMBLE
\providecommand{\DIFadd}[1]{\texorpdfstring{\DIFaddtex{#1}}{#1}} %DIF PREAMBLE
\providecommand{\DIFdel}[1]{\texorpdfstring{\DIFdeltex{#1}}{}} %DIF PREAMBLE
\newcommand{\DIFscaledelfig}{0.5}
%DIF HIGHLIGHTGRAPHICS PREAMBLE %DIF PREAMBLE
\RequirePackage{settobox} %DIF PREAMBLE
\RequirePackage{letltxmacro} %DIF PREAMBLE
\newsavebox{\DIFdelgraphicsbox} %DIF PREAMBLE
\newlength{\DIFdelgraphicswidth} %DIF PREAMBLE
\newlength{\DIFdelgraphicsheight} %DIF PREAMBLE
% store original definition of \includegraphics %DIF PREAMBLE
\LetLtxMacro{\DIFOincludegraphics}{\includegraphics} %DIF PREAMBLE
\newcommand{\DIFaddincludegraphics}[2][]{{\color{blue}\fbox{\DIFOincludegraphics[#1]{#2}}}} %DIF PREAMBLE
\newcommand{\DIFdelincludegraphics}[2][]{% %DIF PREAMBLE
\sbox{\DIFdelgraphicsbox}{\DIFOincludegraphics[#1]{#2}}% %DIF PREAMBLE
\settoboxwidth{\DIFdelgraphicswidth}{\DIFdelgraphicsbox} %DIF PREAMBLE
\settoboxtotalheight{\DIFdelgraphicsheight}{\DIFdelgraphicsbox} %DIF PREAMBLE
\scalebox{\DIFscaledelfig}{% %DIF PREAMBLE
\parbox[b]{\DIFdelgraphicswidth}{\usebox{\DIFdelgraphicsbox}\\[-\baselineskip] \rule{\DIFdelgraphicswidth}{0em}}\llap{\resizebox{\DIFdelgraphicswidth}{\DIFdelgraphicsheight}{% %DIF PREAMBLE
\setlength{\unitlength}{\DIFdelgraphicswidth}% %DIF PREAMBLE
\begin{picture}(1,1)% %DIF PREAMBLE
\thicklines\linethickness{2pt} %DIF PREAMBLE
{\color[rgb]{1,0,0}\put(0,0){\framebox(1,1){}}}% %DIF PREAMBLE
{\color[rgb]{1,0,0}\put(0,0){\line( 1,1){1}}}% %DIF PREAMBLE
{\color[rgb]{1,0,0}\put(0,1){\line(1,-1){1}}}% %DIF PREAMBLE
\end{picture}% %DIF PREAMBLE
}\hspace*{3pt}}} %DIF PREAMBLE
} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddbegin}{\DIFaddbegin} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddend}{\DIFaddend} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelbegin}{\DIFdelbegin} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelend}{\DIFdelend} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddbegin}{\DIFOaddbegin \let\includegraphics\DIFaddincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddend}{\DIFOaddend \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelbegin}{\DIFOdelbegin \let\includegraphics\DIFdelincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelend}{\DIFOaddend \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddbeginFL}{\DIFaddbeginFL} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddendFL}{\DIFaddendFL} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelbeginFL}{\DIFdelbeginFL} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelendFL}{\DIFdelendFL} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddbeginFL}{\DIFOaddbeginFL \let\includegraphics\DIFaddincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddendFL}{\DIFOaddendFL \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelbeginFL}{\DIFOdelbeginFL \let\includegraphics\DIFdelincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelendFL}{\DIFOaddendFL \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
%DIF END PREAMBLE EXTENSION ADDED BY LATEXDIFF

\begin{document}
\maketitle

Sherratt, K. \textsuperscript{1}, Gruson, H. \textsuperscript{1}, Grah, R. \textsuperscript{2}, Johnson, H. \textsuperscript{2}, Niehus, R. \textsuperscript{2}, Prasse, B. \textsuperscript{2}, \DIFdelbegin \DIFdel{Sandman}\DIFdelend \DIFaddbegin \DIFadd{Sandmann}\DIFaddend , F. \textsuperscript{2}, Deuschel, J. \textsuperscript{3}, Wolffram, D. \textsuperscript{3}, Abbott, S. \textsuperscript{1}, Ullrich, A. \textsuperscript{4}, Gibson, G. \textsuperscript{5}, Ray, EL. \textsuperscript{5}, Reich, NG. \textsuperscript{5}, Sheldon, D. \textsuperscript{5}, Wang, Y. \textsuperscript{5}, Wattanachit, N. \textsuperscript{5}, Wang, L. \textsuperscript{6}, Trnka, J. \textsuperscript{7}, Obozinski, G. \textsuperscript{8}, Sun, T. \textsuperscript{8}, Thanou, D. \textsuperscript{8}, Pottier, L. \textsuperscript{9}, Krymova, E. \textsuperscript{10}, Meinke, JH. \textsuperscript{11}, Barbarossa, MV. \textsuperscript{12}, Leithäuser, N. \textsuperscript{13}, Mohring, J. \textsuperscript{13}, Schneider, J. \textsuperscript{13}, Włazło, J. \textsuperscript{13}, Fuhrmann, J. \textsuperscript{14}, Lange, B. \textsuperscript{15}, Rodiah, I. \textsuperscript{15}, Baccam, P. \textsuperscript{16}, Gurung, H. \textsuperscript{16}, Stage, S. \textsuperscript{16}, Suchoski, B. \textsuperscript{16}, Budzinski, J. \textsuperscript{17}, Walraven, R. \textsuperscript{17}, Villanueva, I. \textsuperscript{18}, Tuček, V. \textsuperscript{19}, Šmíd, M. \textsuperscript{20}, Zajíček, M. \textsuperscript{20}, Pérez Álvarez, C. \textsuperscript{21}, Reina, B. \textsuperscript{21}, Bosse, NI. \textsuperscript{1}, Meakin, S. \textsuperscript{1}, Castro, L. \textsuperscript{22}, Fairchild, G. \textsuperscript{22}, Michaud, I. \textsuperscript{22}, Osthus, D. \textsuperscript{22}, Alaimo Di Loro, P. \textsuperscript{23}, Maruotti, A. \textsuperscript{23}, Eclerová, V. \textsuperscript{24}, Kraus, A. \textsuperscript{24}, Kraus, D. \textsuperscript{24}, Pribylova, L. \textsuperscript{24}, Dimitris, B. \textsuperscript{25}, Li, ML. \textsuperscript{25}, Saksham, S. \textsuperscript{25}, Dehning, J. \textsuperscript{26}, Mohr, S. \textsuperscript{26}, Priesemann, V. \textsuperscript{26}, Redlarski, G. \textsuperscript{27}, Bejar, B. \textsuperscript{28}, Ardenghi, G. \textsuperscript{29}, Parolini, N. \textsuperscript{29}, Ziarelli, G. \textsuperscript{29}, Bock, W. \textsuperscript{30}, Heyder, S. \textsuperscript{31}, Hotz, T. \textsuperscript{31}, E. Singh, D. \textsuperscript{32}, Guzman-Merino, M. \textsuperscript{32}, Aznarte, JL. \textsuperscript{33}, Moriña, D. \textsuperscript{34}, Alonso, S. \textsuperscript{35}, Álvarez, E. \textsuperscript{35}, López, D. \textsuperscript{35}, Prats, C. \textsuperscript{35}, Burgard, JP. \textsuperscript{36}, Rodloff, A. \textsuperscript{37}, Zimmermann, T. \textsuperscript{37}, Kuhlmann, A. \textsuperscript{38}, Zibert, J. \textsuperscript{39}, Pennoni, F. \textsuperscript{40}, Divino, F. \textsuperscript{41}, Català, M. \textsuperscript{42}, Lovison, G. \textsuperscript{43}, Giudici, P. \textsuperscript{44}, Tarantino, B. \textsuperscript{44}, Bartolucci, F. \textsuperscript{45}, Jona Lasinio, G. \textsuperscript{46}, Mingione, M. \textsuperscript{46}, Farcomeni, A. \textsuperscript{47}, Srivastava, A. \textsuperscript{48}, Montero-Manso, P. \textsuperscript{49}, Adiga, A. \textsuperscript{50}, Hurt, B. \textsuperscript{50}, Lewis, B. \textsuperscript{50}, Marathe, M. \textsuperscript{50}, Porebski, P. \textsuperscript{50}, Venkatramanan, S. \textsuperscript{50}, Bartczuk, R. \textsuperscript{51}, Dreger, F. \textsuperscript{51}, Gambin, A. \textsuperscript{51}, Gogolewski, K. \textsuperscript{51}, Gruziel-Słomka, M. \textsuperscript{51}, Krupa, B. \textsuperscript{51}, Moszynski, A. \textsuperscript{51}, Niedzielewski, K. \textsuperscript{51}, Nowosielski, J. \textsuperscript{51}, Radwan, M. \textsuperscript{51}, Rakowski, F. \textsuperscript{51}, Semeniuk, M. \textsuperscript{51}, Szczurek, E. \textsuperscript{51}, Zieliński, J. \textsuperscript{51}, Kisielewski, J. \textsuperscript{52}, Pabjan, B. \textsuperscript{53}, Holger, K. \textsuperscript{54}, Kheifetz, Y. \textsuperscript{54}, Scholz, M. \textsuperscript{54}, Biecek, P. \textsuperscript{55}, Bodych, M. \textsuperscript{56}, Filinski, M. \textsuperscript{56}, Idzikowski, R. \textsuperscript{56}, Krueger, T. \textsuperscript{56}, Ozanski, T. \textsuperscript{56}, Bracher, J. \textsuperscript{3}, Funk, S. \textsuperscript{1}

\textsuperscript{1}London School of Hygiene \& Tropical Medicine, \textsuperscript{2}European Centre for Disease Prevention and Control (ECDC), \textsuperscript{3}Karlsruhe Institute of Technology, \textsuperscript{4}Robert Koch Institute, \textsuperscript{5}University of Massachusetts Amherst, \textsuperscript{6}Boston Children's Hospital and Harvard Medical School, \textsuperscript{7}Charles University, \textsuperscript{8}École Polytechnique Fédérale de Lausanne, \textsuperscript{9}Éducation nationale, \textsuperscript{10}Eidgenössische Technische Hochschule Zürich, \textsuperscript{11}Forschungszentrum Jülich GmbH, \textsuperscript{12}Frankfurt Institute for Advanced Studies, \textsuperscript{13}Fraunhofer Institute for Industrial Mathematics, \textsuperscript{14}Heidelberg University, \textsuperscript{15}Helmholtz Centre for Infection Research, \textsuperscript{16}IEM, Inc., \textsuperscript{17}Independent, \textsuperscript{18}Institut d'Investigacions Biomèdiques August Pi i Sunyer (IDIBAPS), Universitat Pompeu Fabra, \textsuperscript{19}Institute of Computer Science of the CAS, \textsuperscript{20}Institute of Information Theory and Automation of the CAS, \textsuperscript{21}Inverence, \textsuperscript{22}Los Alamos National Laboratory, \textsuperscript{23}LUMSA University, \textsuperscript{24}Masaryk University, \textsuperscript{25}Massachusetts Institute of Technology, \textsuperscript{26}Max-Planck-Institut für Dynamik und Selbstorganisation, \textsuperscript{27}Medical University of Gdansk, \textsuperscript{28}Paul Scherrer Institute, \textsuperscript{29}Politecnico di Milano, \textsuperscript{30}Technical University of Kaiserlautern, \textsuperscript{31}Technische Universität Ilmenau, \textsuperscript{32}Universidad Carlos III de Madrid, \textsuperscript{33}Universidad Nacional de Educación a Distancia (UNED), \textsuperscript{34}Universitat de Barcelona, \textsuperscript{35}Universitat Politècnica de Catalunya, \textsuperscript{36}Universität Trier, \textsuperscript{37}University of Cologne, \textsuperscript{38}University of Halle, \textsuperscript{39}University of Ljubljana, \textsuperscript{40}University of Milano-Bicocca, \textsuperscript{41}University of Molise, \textsuperscript{42}University of Oxford, \textsuperscript{43}University of Palermo, \textsuperscript{44}University of Pavia, \textsuperscript{45}University of Perugia, \textsuperscript{46}University of Rome ``La Sapienza'', \textsuperscript{47}University of Rome ``Tor Vergata'', \textsuperscript{48}University of Southern California, \textsuperscript{49}University of Sydney, \textsuperscript{50}University of Virginia, \textsuperscript{51}University of Warsaw, \textsuperscript{52}University of Warsaw, University of Bialystok, \textsuperscript{53}University of Wroclaw, \textsuperscript{54}Universtät Leipzig, \textsuperscript{55}Warsaw University of Technology, \textsuperscript{56}Wroclaw University of Science and Technology

\hypertarget{abstract}{%
\section{Abstract}\label{abstract}}

\emph{Background:} Short-term forecasts of infectious disease burden can contribute to situational awareness and aid capacity planning. Based on best practice in other fields and recent insights in infectious disease epidemiology, one can maximise the predictive performance of such forecasts if multiple models are combined into an ensemble. Here we report on the performance of ensembles in predicting COVID-19 cases and deaths across Europe between 08 March 2021 and 07 March 2022.

\emph{Methods:} We used open-source tools to develop a public European COVID-19 Forecast Hub. We invited groups globally to contribute weekly forecasts for COVID-19 cases and deaths reported \DIFdelbegin \DIFdel{from }\DIFdelend \DIFaddbegin \DIFadd{by }\DIFaddend a standardised source \DIFaddbegin \DIFadd{for 32 countries }\DIFaddend over the next one to four weeks. Teams submitted forecasts from March 2021 using standardised quantiles of the predictive distribution. Each week we created an ensemble forecast, where each predictive quantile was calculated as the equally-weighted average (initially the mean and then from 26th July the median) of all individual models' predictive quantiles. We measured the performance of each model using the relative Weighted Interval Score (WIS), comparing models' forecast accuracy relative to all other models. We retrospectively explored alternative methods for ensemble forecasts, including weighted averages based on models' past predictive performance.

\emph{Results:} Over 52 weeks we collected \DIFdelbegin \DIFdel{and combined up to 28 forecast modelsfor 32 countries. We }\DIFdelend \DIFaddbegin \DIFadd{forecasts from 48 unique models. We evaluated 29 models' forecast scores in comparison to the ensemble model. We }\DIFaddend found a weekly ensemble had a consistently strong performance across countries over time. Across all horizons and locations, the ensemble performed better on relative WIS than \DIFdelbegin \DIFdel{84}\DIFdelend \DIFaddbegin \DIFadd{83}\DIFaddend \% of participating models' forecasts of incident cases (with a total N=\DIFdelbegin \DIFdel{862}\DIFdelend \DIFaddbegin \DIFadd{886 predictions from 23 unique models}\DIFaddend ), and \DIFdelbegin \DIFdel{92}\DIFdelend \DIFaddbegin \DIFadd{91}\DIFaddend \% of participating models' forecasts of deaths (N=\DIFdelbegin \DIFdel{746}\DIFdelend \DIFaddbegin \DIFadd{763 predictions from 20 models}\DIFaddend ). Across a one to four week time horizon, ensemble performance declined with longer forecast periods when forecasting cases, but remained stable over four weeks for incident death forecasts. In every forecast across 32 countries, the ensemble outperformed most contributing models when forecasting either cases or deaths, frequently outperforming all of its individual component models. Among several choices of ensemble methods we found that the most influential and best choice was to use a median average of models instead of using the mean, regardless of methods of weighting component forecast models.

\emph{Conclusions:} Our results support the use of combining forecasts from individual models into an ensemble in order to improve predictive performance across epidemiological targets and populations during infectious disease epidemics. Our findings further suggest that median ensemble methods yield better predictive performance more than ones based on means. Our findings also highlight that forecast consumers should place more weight on incident death forecasts than incident case forecasts at forecast horizons greater than two weeks.

\emph{Code and data availability:} All data and code are publicly available on Github: \href{https://github.com/covid19-forecast-hub-europe/euro-hub-ensemble}{covid19-forecast-hub-europe/euro-hub-ensemble}.

\hypertarget{background}{%
\section{Background}\label{background}}

Epidemiological forecasts make quantitative statements about a disease outcome in the near future. Forecasting targets can include measures of prevalent or incident disease and its severity, for some population over a specified time horizon. Researchers, policy makers, and the general public have used such forecasts to understand and respond to the global outbreaks of COVID-19 \protect\hyperlink{ref-basshuysenThreeWaysWhich2021}{{[}1{]}}--\protect\hyperlink{ref-europeancentrefordiseasepreventionandcontrolForecastingCOVID19Cases2021}{{[}3{]}}. \DIFdelbegin %DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{Forecasters }\DIFdelend \DIFaddbegin \DIFadd{At the same time, forecasters }\DIFaddend use a variety of methods and models for creating and publishing forecasts, varying in both defining the forecast outcome and in reporting the probability distribution of outcomes \protect\hyperlink{ref-zelnerAccountingUncertaintyPandemic2021}{{[}4{]}}, \protect\hyperlink{ref-jamesUseMisuseMathematical2021}{{[}5{]}}.
\DIFdelbegin \DIFdel{Such variation }\DIFdelend \DIFaddbegin 

\DIFadd{Within Europe, comparing forecasts across both models and countries can support a range of national policy needs simultaneously. European public health professionals operate across national, regional, and continental scales, with strong existing policy networks in addition to rich patterns of cross-border migration influencing epidemic dynamics. A majority of European countries also cooperate in setting policy with inter-governmental European bodies such as the European Centre for Disease Prevention and Control (ECDC). In this case, a consistent approach to forecasting across the continent as a whole can support accurately informing cross-European monitoring, analysis, and guidance }\protect\hyperlink{ref-europeancentrefordiseasepreventionandcontrolForecastingCOVID19Cases2021}{{[}3{]}}\DIFadd{. At a regional level, multi-country forecasts can support a better understanding of the impact of regional migration networks. Meanwhile, where there is limited capacity for infectious disease forecasting at a national level, forecasters generating multi-country results can provide an otherwise-unavailable opportunity for forecasts to inform national situational awareness. Some independent forecasting models have sought to address this by producing multi-country results }\protect\hyperlink{ref-aguasModellingCOVID19Pandemic2020}{{[}6{]}}\DIFadd{--}\protect\hyperlink{ref-agostoMonitoringCOVID19Contagion2021}{{[}9{]}}\DIFadd{.
}

\DIFadd{Variation in forecast methods and presentation }\DIFaddend makes it difficult to compare predictive performance between forecast models, and from there to derive objective arguments for using one forecast over another. This confounds the selection of a single representative forecast and reduces the reliability of the evidence base for decisions based on forecasts. \DIFdelbegin %DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdelend A ``forecast hub'' is a centralised effort to improve the transparency and usefulness of forecasts, by standardising and collating the work of many independent teams producing forecasts \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-reichCollaborativeMultiyearMultimodel2019}{{[}6{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-reichCollaborativeMultiyearMultimodel2019}{{[}10{]}}\DIFaddend . A hub sets a commonly agreed-upon structure for forecast targets, such as type of disease event, spatio-temporal units, or the set of quantiles of the probability distribution to include from probabilistic forecasts. For instance, a hub may collect predictions of the total number of cases reported in a given country for each day in the next two weeks. Forecasters can adopt this format and contribute forecasts for centralised storage in the public domain.
\DIFaddbegin 

\DIFaddend This shared infrastructure allows forecasts produced from diverse teams and methods to be visualised and quantitatively compared on a like-for-like basis, which can strengthen public and policy use of disease forecasts. The underlying approach to creating a forecast hub was pioneered in climate modelling and adapted for collaborative epidemiological forecasts of dengue \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-johanssonOpenChallengeAdvance2019}{{[}7{]}} %%%
\DIFdelend \DIFaddbegin \hyperlink{ref-johanssonOpenChallengeAdvance2019}{{[}11{]}} \DIFaddend and influenza in the USA \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-reichCollaborativeMultiyearMultimodel2019}{{[}6{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-reichCollaborativeMultiyearMultimodel2019}{{[}10{]}}\DIFaddend , \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-reichAccuracyRealtimeMultimodel2019}{{[}8{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-reichAccuracyRealtimeMultimodel2019}{{[}12{]}}\DIFaddend . This infrastructure was adapted for forecasts of short-term COVID-19 cases and deaths in the US \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-cramerUnitedStatesCOVID192021}{{[}9{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-cramerUnitedStatesCOVID192021}{{[}13{]}}\DIFaddend , \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-rayEnsembleForecastsCoronavirus2020e}{{[}10{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-rayEnsembleForecastsCoronavirus2020e}{{[}14{]}}\DIFaddend , prompting similar efforts in some European countries \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-bracherPreregisteredShorttermForecasting2021}{{[}11{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-bracherPreregisteredShorttermForecasting2021}{{[}15{]}}\DIFaddend --\protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-bicherSupportingCOVID19PolicyMaking2021}{{[}13{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-bicherSupportingCOVID19PolicyMaking2021}{{[}17{]}}\DIFaddend .

Standardising forecasts allows for combining multiple forecasts into a single ensemble with the potential for an improved predictive performance. Evidence from previous efforts in multi-model infectious disease forecasting suggests that forecasts from an ensemble of models can be consistently high performing compared to any one of the component models \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-johanssonOpenChallengeAdvance2019}{{[}7{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-johanssonOpenChallengeAdvance2019}{{[}11{]}}\DIFaddend , \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-reichAccuracyRealtimeMultimodel2019}{{[}8{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-reichAccuracyRealtimeMultimodel2019}{{[}12{]}}\DIFaddend , \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-viboudRAPIDDEbolaForecasting2018}{{[}14{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-viboudRAPIDDEbolaForecasting2018}{{[}18{]}}\DIFaddend . Elsewhere, weather forecasting has a long-standing use of building ensembles of models using diverse methods with standardised data and formatting in order to improve performance \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-buizzaIntroductionSpecialIssue2019}{{[}15{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-buizzaIntroductionSpecialIssue2019}{{[}19{]}}\DIFaddend , \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-moranEpidemicForecastingMessier2016}{{[}16{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-moranEpidemicForecastingMessier2016}{{[}20{]}}\DIFaddend .

The European COVID-19 Forecast Hub \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-europeancovid-19forecasthubEuropeanCOVID19Forecast2021}{{[}17{]}} %%%
\DIFdelend \DIFaddbegin \hyperlink{ref-europeancovid-19forecasthubEuropeanCOVID19Forecast2021}{{[}21{]}} \DIFaddend is a project to collate short term forecasts of COVID-19 across 32 countries in the European region. The Hub is funded and supported by the \DIFdelbegin \DIFdel{European Centre for Disease Prevention and Control (ECDC)}\DIFdelend \DIFaddbegin \DIFadd{ECDC}\DIFaddend , with the primary aim to provide reliable information about the near-term epidemiology of the COVID-19 pandemic to the research and policy communities and the general public \protect\hyperlink{ref-europeancentrefordiseasepreventionandcontrolForecastingCOVID19Cases2021}{{[}3{]}}. Second, the Hub aims to create infrastructure for storing and analysing epidemiological forecasts made in real time by diverse research teams and methods across Europe. Third, the Hub aims to maintain a community of infectious disease modellers underpinned by open science principles.

We started formally collating and combining contributions to the European Forecast Hub in March 2021. Here, we investigate the predictive performance of an ensemble of all forecasts contributed to the Hub in real time each week, as well as the performance of variations of ensemble methods created retrospectively.

\hypertarget{methods}{%
\section{Methods}\label{methods}}

We developed infrastructure to host and analyse prospective forecasts of COVID-19 cases and deaths. The infrastructure is compatible with equivalent research software from the US \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-cramerReichlabCovid19forecasthubRelease2021}{{[}18{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-cramerReichlabCovid19forecasthubRelease2021}{{[}22{]}}\DIFaddend , \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-wangReichlabCovidHubUtilsRepository2021}{{[}19{]}} %%%
\DIFdelend \DIFaddbegin \hyperlink{ref-wangReichlabCovidHubUtilsRepository2021}{{[}23{]}} \DIFaddend and German and Polish COVID-19 \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-bracherGermanPolishCOVID192020}{{[}20{]}} %%%
\DIFdelend \DIFaddbegin \hyperlink{ref-bracherGermanPolishCOVID192020}{{[}24{]}} \DIFaddend Forecast Hubs, and easy to replicate for new forecasting collaborations.

\hypertarget{forecast-targets-and-models}{%
\subsubsection{Forecast targets and models}\label{forecast-targets-and-models}}

We sought forecasts for the incidence of COVID-19 as the total reported number of cases and deaths per week. We considered forecasts for 32 countries in Europe, including all countries of the European Union, European Free Trade Area, and the United Kingdom. We compared forecasts against observed data reported for each country by Johns Hopkins University (JHU, \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-dongInteractiveWebbasedDashboard2020}{{[}21{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-dongInteractiveWebbasedDashboard2020}{{[}25{]}}\DIFaddend ). JHU data sources included a mix of national and aggregated subnational data. We aggregated incidence over the Morbidity and Mortality Weekly Report (MMWR) epidemiological week definition of Sunday through Saturday.

Teams could express their uncertainty around any single forecast target by submitting predictions for up to 23 quantiles (from 0.01 to 0.99) of the predictive probability distribution. Teams could also submit a single point forecast. At the first submission we asked teams to add a pre-specified set of metadata briefly describing the forecasting team and methods (see supplementary information (SI)). No restrictions were placed on who could submit forecasts. To increase participation we actively contacted known forecasting teams across Europe and the US and advertised among the ECDC network. Teams submitted a broad spectrum of model types, ranging from mechanistic to empirical models, agent-based and statistical models, and ensembles of multiple quantitative or qualitative models (described at \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-europeancovid-19forecasthubCommunity}{{[}22{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-europeancovid-19forecasthubCommunity}{{[}26{]}}\DIFaddend ). We maintain a full project specification with a detailed submissions protocol \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-europeancovid-19forecasthubCovid19forecasthubeuropeWiki}{{[}23{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-europeancovid-19forecasthubCovid19forecasthubeuropeWiki}{{[}27{]}}\DIFaddend .

We collected forecasts submitted weekly in real time over the 52 week period from 08 March 2021 to 07 March 2022. Teams submitted at latest two days after the complete dataset for the latest forecasting week became available each Sunday. We implemented an automated validation programme to check that each new forecast conformed to standardised formatting. Forecast validation ensured a monotonic increase of predictions with each increasing quantile, integer-valued non-negative counts of predicted cases, as well as consistent date and location definitions.

Each week we used all available valid forecasts to create a weekly real-time ensemble model (referred to as ``the ensemble'' from here on), for each of the 256 possible forecast targets: incident cases and deaths in 32 locations over the following one through four weeks. The ensemble method was an unweighted average of all models' forecast values, at each predictive quantile for a given location, target, and horizon. From 08 March 2021, we used the arithmetic mean. However we noticed that including highly anomalous forecasts in a mean ensemble produced extremely wide uncertainty. To mitigate this, from 26\textsuperscript{th} July 2021 onwards the ensemble instead used a median of all predictive quantiles.

We created an open and publicly accessible interface to the forecasts and ensemble, including an online visualisation tool allowing viewers to see past data and interact with one or multiple forecasts for each country and target for up to four weeks' horizon \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-europeancovid-19forecasthubEuropeanCovid19Forecast}{{[}24{]}}%%%
\DIFdel{. All forecast and meta data }\DIFdelend \DIFaddbegin \hyperlink{ref-europeancovid-19forecasthubEuropeanCovid19Forecast}{{[}28{]}}\DIFadd{. All forecasts, metadata, and evaluations }\DIFaddend are freely available and held on Github \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-europeancovid-19forecasthubEuropeanCOVID19Forecast2021}{{[}17{]}} %%%
\DIFdelend \DIFaddbegin \hyperlink{ref-europeancovid-19forecasthubEuropeanCOVID19Forecast2021}{{[}21{]}} \DIFadd{(archived in real-time at }\protect\hyperlink{ref-katharine_sherratt_2022_7356267}{{[}29{]}}\DIFadd{), }\DIFaddend and Zoltar, a platform for hosting epidemiological forecasts \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-epiforecastsProjectECDCEuropean2021}{{[}25{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-epiforecastsProjectECDCEuropean2021}{{[}30{]}}\DIFaddend , \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-reichZoltarForecastArchive2021}{{[}26{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-reichZoltarForecastArchive2021}{{[}31{]}}\DIFaddend . In the codebase for this study \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-PredictivePerformanceMultimodel2022}{{[}27{]}} %%%
\DIFdelend \DIFaddbegin \hyperlink{ref-PredictivePerformanceMultimodel2022}{{[}32{]}} \DIFaddend we provide a simple method and instructions for downloading and preparing these data for analysis using R. We encourage other researchers to freely use and adapt this to support their own analyses.

\hypertarget{forecast-evaluation}{%
\subsubsection{Forecast evaluation}\label{forecast-evaluation}}

In this study we \DIFdelbegin \DIFdel{focus }\DIFdelend \DIFaddbegin \DIFadd{focused }\DIFaddend only on the comparative performance of forecasting models relative to each other. \DIFaddbegin \DIFadd{Performance in absolute terms is available on the Hub website }\protect\hyperlink{ref-europeancovid-19forecasthubEuropeanCovid19Forecast}{{[}28{]}}\DIFadd{. }\DIFaddend For each model, we \DIFdelbegin \DIFdel{evaluated performance in terms of both accuracy (coverage) }\DIFdelend \DIFaddbegin \DIFadd{assessed calibration }\DIFaddend and overall predictive performance\DIFdelbegin \DIFdel{(weighted interval score)}\DIFdelend . We evaluated all previous forecasts against actual observed values for each model, stratified by the forecast horizon, location, and target. We calculated scores using the \emph{scoringutils} R package \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-nikosibosseScoringutilsUtilitiesScoring2020}{{[}28{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-nikosibosseScoringutilsUtilitiesScoring2020}{{[}33{]}}\DIFaddend . We removed any forecast surrounding (both the week of, and the first week after) a strongly anomalous data point. We defined anomalous as where any subsequent data release revised that data point by over 5\%.

\DIFaddbegin \DIFadd{To investigate calibration we assessed coverage as the correspondence between the forecast probability of an event and the observed frequency of that event. This usage follows previous work in epidemic forecasting }\protect\hyperlink{ref-bracherEvaluatingEpidemicForecasts2021}{{[}34{]}}\DIFadd{, and is related to the concept of reliability for binary forecasts. }\DIFaddend We established the accuracy of each model's prediction boundaries as the coverage of the predictive intervals. We calculated coverage at a given interval level \DIFdelbegin \DIFdel{k}\DIFdelend \DIFaddbegin \DIFadd{\(k\)}\DIFaddend , where \(k\in[0,1]\), as the proportion \(p\) of observations that fell within the corresponding central predictive intervals across locations and forecast dates. A perfectly calibrated model would have \(p=k\) at all 11 levels (corresponding to 22 quantiles excluding the median). An underconfident model at level \(k\) would have \(p>k\), i.e.~more observations fall within a given interval than expected. In contrast, an overconfident model at level \(k\) would have \(p<k\), i.e.~fewer observations fall within a given interval than expected. We here focus on coverage at the \(k=0.5\) and \(k=0.95\) levels.

We also assessed the overall predictive performance of weekly forecasts using the \DIFdelbegin \DIFdel{weighted interval score }\DIFdelend \DIFaddbegin \DIFadd{Weighted Interval Score\textasciitilde}\DIFaddend (WIS) across all available quantiles. The WIS represents a parsimonious approach to scoring forecasts based on uncertainty represented as forecast values across a set of quantiles \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-bracherEvaluatingEpidemicForecasts2021}{{[}29{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-bracherEvaluatingEpidemicForecasts2021}{{[}34{]}}\DIFaddend , and is a strictly proper scoring rule, that is, it is optimal for predictions that come from the data-generating model. As a consequence, the WIS encourages forecasters to report predictions representing their true belief about the future \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-gneitingStrictlyProperScoring2007}{{[}30{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-gneitingStrictlyProperScoring2007}{{[}35{]}}\DIFaddend . Each forecast for a given location and date is scored based on an observed count of weekly incidence, the median of the predictive distribution and the predictive upper and lower quantiles corresponding to the central predictive interval level.

Not all models provided forecasts for all locations and dates, and we needed to compare predictive performance in the face of various levels of missingness across each forecast target. Therefore we calculated a relative WIS. This is a measure of forecast performance which takes into account that different teams may not cover the same set of forecast targets (i.e., weeks and locations). The relative WIS is computed using a \emph{pairwise comparison tournament} where for each pair of models a mean score ratio is computed based on the set of shared targets. The relative WIS of a model with respect to another model is then the ratio of their respective geometric mean of the mean score ratios, such that smaller values indicate better performance.

We scaled the relative WIS of each model with the relative WIS of a baseline model, for each forecast target, location, date, and horizon. The baseline model assumes case or death counts stay the same as the latest data point over all future horizons, with expanding uncertainty, described previously in \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-cramerEvaluationIndividualEnsemble2021}{{[}31{]}}%%%
\DIFdel{. Here }\DIFdelend \DIFaddbegin \hyperlink{ref-cramerEvaluationIndividualEnsemble2021}{{[}36{]}}\DIFadd{. In this study }\DIFaddend we report the relative WIS of each model with respect to the baseline model.

\hypertarget{retrospective-ensemble-methods}{%
\paragraph{Retrospective ensemble methods}\label{retrospective-ensemble-methods}}

We retrospectively explored alternative methods for combining forecasts for each target at each week. A natural way to combine probability distributions available in the quantile format \DIFaddbegin \protect\hyperlink{ref-genestVincentizationRevisited1992}{{[}37{]}} \DIFaddend used here is
\DIFdelbegin %DIFDELCMD < \protect\hyperlink{ref-genestVincentizationRevisited1992}{{[}32{]}}
%DIFDELCMD < %%%
\DIFdelend 

\[F^{-1}(\alpha) = \sum_{i=1}^{n}w_i F_i^{-1}(\alpha)\DIFaddbegin \DIFadd{,}\DIFaddend \]
\DIFdelbegin \DIFdel{,
}\DIFdelend 

Where \(F_{1} \ldots F_{n}\) are the cumulative distribution functions of the individual probability distributions (in our case, the predictive distributions of each forecast model \(i\) contributed to the hub), \(w_i\) are a set of weights in \([0,1]\); and \(\alpha\) are the quantile levels\DIFdelbegin \DIFdel{such that
}\DIFdelend \DIFaddbegin \DIFadd{, such that following notation introduced in }\protect\hyperlink{ref-genestVincentizationRevisited1992}{{[}37{]}}\DIFadd{,
}\DIFaddend 

\[F^{-1}(\alpha) = \mathrm{inf} \{t : F_i(t) \geq \alpha \}\DIFaddbegin \DIFadd{.}\DIFaddend \]
\DIFdelbegin \DIFdel{.
}\DIFdelend 

Different ensemble choices then mainly translate to the choice of weights \(w_i\). An arithmetic mean ensemble uses weights at \(w_i=1/n\), where all weights are equal and sum up to 1.

Alternatively, we can choose a set of weights to apply to forecasts before they are combined. Numerous options exist for choosing these weights with the aim to maximise predictive performance, including choosing weights to reflect each forecast's past performance (thereby moving from an untrained to a trained ensemble). A straightforward choice is so-called inverse score weighting. In this case, the weights are calculated as

\[w_i = \frac{1}{S_i}\DIFaddbegin \DIFadd{,}\DIFaddend \]
\DIFdelbegin \DIFdel{,
}\DIFdelend 

where \(S_i\) reflects the forecasting skill \DIFaddbegin \DIFadd{calculated as the relative WIS }\DIFaddend of forecaster \(i\), \DIFaddbegin \DIFadd{calculated over all available model data, and }\DIFaddend normalised so that weights sum to 1. This method of weighting was found in the US to outperform unweighted scores during some time periods \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-taylorCombiningProbabilisticForecasts2021}{{[}33{]}} %%%
\DIFdelend \DIFaddbegin \hyperlink{ref-taylorCombiningProbabilisticForecasts2021}{{[}38{]}} \DIFaddend but this was not confirmed in a similar study in Germany and Poland \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-bracherPreregisteredShorttermForecasting2021}{{[}11{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-bracherPreregisteredShorttermForecasting2021}{{[}15{]}}\DIFaddend .

When constructing ensembles from quantile means, a single outlier can have an oversized effect on the ensemble forecast. Previous research has found that a median ensemble, replacing the arithmetic mean of each quantile with a median of the same values, yields competitive performance while maintaining robustness to outlying forecasts \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-rayComparingTrainedUntrained2022}{{[}34{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-rayComparingTrainedUntrained2022}{{[}39{]}}\DIFaddend . Building on this, we also created weighted median ensembles using the weights described above and a Harrel-Davis quantile estimator with a beta function to approximate the weighted percentiles \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-harrellNewDistributionfreeQuantile1982}{{[}35{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-harrellNewDistributionfreeQuantile1982}{{[}40{]}}\DIFaddend . We then compared the performance of unweighted and inverse relative WIS weighted mean and median ensembles.

\hypertarget{results}{%
\section{Results}\label{results}}

\DIFaddbegin \DIFadd{For 32 European countries, we collected, visualised, and made available online weekly COVID-19 forecasts and observed data }\protect\hyperlink{ref-katharine_sherratt_2022_7356267}{{[}29{]}}\DIFadd{. }\DIFaddend An example of weekly forecasts from the ensemble model is shown in Figure \ref{fig:example-ensemble}.

\begin{figure}
\centering
\includegraphics{latest_files/figure-latex/example-ensemble-1.pdf}
\caption{\label{fig:example-ensemble}\emph{Ensemble forecasts of weekly incident cases in Germany over periods of increasing SARS-CoV-2 variants Delta (B.1.617.2, left) and Omicron (B.1.1.529, right). Black indicates observed data. Coloured ribbons represent each weekly forecast of 1-4 weeks ahead (showing median, 50\%, and 90\% probability). For each variant, forecasts are shown over an x-axis bounded by the earliest dates at which 5\% and 99\% of sequenced cases were identified as the respective variant of concern, while vertical dotted lines indicate the approximate date that the variant reached dominance (\textgreater50\% sequenced cases).}}
\end{figure}

Over the whole study period, \DIFdelbegin \DIFdel{26 independently participating forecasting teams contributed results from 28 unique forecasting models(see supplementary information (SI), Table 1). The }\DIFdelend \DIFaddbegin \DIFadd{we collected forecasts from 48 unique models. Modellers created forecasts choosing from a set of 32 possible locations, four time horizons, and two variables, and modellers variously joined and left the Hub over time. This meant the }\DIFaddend number of models contributing to \DIFdelbegin \DIFdel{each ensemble forecast }\DIFdelend \DIFaddbegin \DIFadd{the Hub }\DIFaddend varied over time and by forecasting target\DIFaddbegin \DIFadd{. Of the total 48 models, we received the most forecasts for Germany, with 29 unique models submitting one-week case forecasts, while only 12 models ever submitted four-week case or death forecasts for Liechtenstein. Modelling teams also differed in how they expressed uncertainty. Only 3 models provided point forecasts with no estimate of uncertainty around their predictions, while 41 models provided the full set of 23 probabilistic quantiles across the predictive distribution for each target.
}

\DIFadd{In this evaluation we included 29 models in comparison to the ensemble forecast }\DIFaddend (SI Figure 1). \DIFdelbegin \DIFdel{Not all modellers created forecasts for all locations, horizons, or variables}\DIFdelend \DIFaddbegin \DIFadd{We have included metadata provided by modellers in the supplement (SI Table 1), and also online }\protect\hyperlink{ref-katharine_sherratt_2022_7356267}{{[}29{]}}\DIFaddend . At most, 15 models contributed forecasts for cases in Germany at the 1 week horizon, with an accumulated 592 \DIFdelbegin \DIFdel{forecasts }\DIFdelend \DIFaddbegin \DIFadd{forecast scores }\DIFaddend for that single target over the study period. In contrast, deaths in Finland at the 2 week horizon saw the smallest number of forecasts, with only 6 independent models contributing \DIFdelbegin \DIFdel{a total }\DIFdelend 24 \DIFdelbegin \DIFdel{forecasts. Similarly, not all teams forecast across all quantiles of the predictive distribution for each target, with only 23 models providing }\DIFdelend \DIFaddbegin \DIFadd{forecast scores at any time over the 52 week period. Of the 29 models included in this evaluation, 5 models provided less than }\DIFaddend the full set of 23 quantiles\DIFaddbegin \DIFadd{, and were excluded when creating the ensemble}\DIFaddend . No ensemble forecast was composed of less than 3 independent models.

Using all models and the ensemble, we created \DIFdelbegin \DIFdel{2106 }\DIFdelend \DIFaddbegin \DIFadd{2139 }\DIFaddend forecasting scores where each score summarises a unique combination of forecasting model, variable, country, and week ahead horizon (SI Figure 2). We visually compared the absolute performance of forecasts in predicting numbers of incident cases and deaths. We observed that forecasts predicted well in times of stable epidemic behaviour, while struggling to accurately predict at longer horizons around inflection points, for example during rapid changes in population-level behaviour or surveillance. Forecast models varied widely in their ability to predict and account for the introduction of new variants, giving the ensemble forecast over these periods a high level of uncertainty (Figure \ref{fig:example-ensemble}).

In relative terms, the ensemble of all models performed well compared to both its component models and the baseline. By relative WIS scaled against a baseline of 1 (where a score \textless1 indicates outperforming the baseline), the median score \DIFdelbegin \DIFdel{for participating models across all submitted forecasts was 1.04, while }\DIFdelend \DIFaddbegin \DIFadd{of forecasts from the Hub ensemble model was 0.71, within an interquartile range of 0.61 at 25\% probability to 0.88 at 75\% probability. Meanwhile }\DIFaddend the median score of forecasts \DIFdelbegin \DIFdel{from the ensemble model was 0.71.
}\DIFdelend \DIFaddbegin \DIFadd{across all participating models (excluding the Hub ensemble) was 1.04 (IQR 0.82-1.36).
}

\DIFaddend Across all horizons and locations, the ensemble performed better on scaled relative WIS than \DIFdelbegin \DIFdel{84\% of participating model }\DIFdelend \DIFaddbegin \DIFadd{83\% of forecast }\DIFaddend scores when forecasting cases (with a total N=\DIFdelbegin \DIFdel{862}\DIFdelend \DIFaddbegin \DIFadd{886 from 23 unique models}\DIFaddend ), and \DIFdelbegin \DIFdel{92\% of participating model }\DIFdelend \DIFaddbegin \DIFadd{91\% of }\DIFaddend scores for forecasts of incident deaths (N=\DIFdelbegin \DIFdel{746). }\DIFdelend \DIFaddbegin \DIFadd{763 scores from 20 models). We also saw high performance from the ensemble when evaluating against all models including those who did not submit the full set of probabilistic quantile predictions (80\% for cases with N=1006 scores from 28 models, and 88\% for deaths, N=877 scores from 24 models).
}\DIFaddend 

\begin{figure}
\centering
\includegraphics{latest_files/figure-latex/performance-horizon-1.pdf}
\caption{\label{fig:performance-horizon}\emph{Performance of short-term forecasts aggregated across all individually submitted models and the Hub ensemble, by horizon, forecasting cases (left) and deaths (right). Performance measured by relative weighted interval score scaled against a baseline (dotted line, 1), and coverage of uncertainty at the 50\% and 95\% levels. Boxplot, with width proportional to number of observations, show interquartile ranges with outlying scores as faded points. The target range for each set of scores is shaded in yellow.}}
\end{figure}

The performance of individual and ensemble forecasts varied by length of the forecast horizon (Figure \ref{fig:performance-horizon}). At each horizon, the typical performance of the ensemble outperformed both the baseline model and the aggregated scores of all its component models, although we saw wide variation between individual models in performance across horizons. Both individual models and the ensemble saw a trend of worsening performance at longer horizons when forecasting cases with the median scaled relative WIS of the ensemble across locations worsened from 0.62 for one-week ahead forecasts to 0.9 when forecasting four weeks ahead. Performance for forecasts of deaths was more stable over one through four weeks, with median ensemble performance moving from 0.69 to 0.76 across the four week horizons.

We observed similar trends in performance across horizon when considering how well the ensemble was calibrated with respect to the observed data. At one week ahead the case ensemble was well calibrated (ca. 50\% and 95\% nominal coverage at the 50\% and 95\% levels respectively). This did not hold at longer forecast horizons as the case forecasts became increasingly over-confident. Meanwhile, the ensemble of death forecasts was well calibrated at the 95\% level across all horizons, and the calibration of death forecasts at the 50\% level improved with lengthening horizons compared to being underconfident at shorter horizons.

\begin{figure}
\centering
\includegraphics{latest_files/figure-latex/performance-countries-1.pdf}
\caption{\label{fig:performance-countries}\emph{Performance of short-term forecasts across models and
median ensemble (asterisk), by country, forecasting cases (top) and deaths (bottom) for two-week ahead forecasts, according to the relative weighted interval score. Boxplots show interquartile ranges, with outliers as faded points, and the ensemble model performance is marked by an asterisk. y-axis is cut-off to an upper bound of 4 for readability.}}
\end{figure}

The ensemble also performed consistently well in comparison to individual models when forecasting across countries (Figure \ref{fig:performance-countries}). In total, across 32 countries forecasting for one through four weeks, when forecasting cases the ensemble outperformed 75\% of component models in \DIFdelbegin \DIFdel{21 }\DIFdelend \DIFaddbegin \DIFadd{22 }\DIFaddend countries, and outperformed all available models in 3 countries. When forecasting deaths, the ensemble outperformed 75\% and 100\% of models in 30 and \DIFdelbegin \DIFdel{9 }\DIFdelend \DIFaddbegin \DIFadd{8 }\DIFaddend countries respectively. Considering only the the two-week horizon shown in Figure \ref{fig:performance-countries}, the ensemble of case forecasts outperformed 75\% models in \DIFdelbegin \DIFdel{24 }\DIFdelend \DIFaddbegin \DIFadd{25 }\DIFaddend countries and all models in only 12 countries. At the two-week horizon for forecasts of deaths, the ensemble outperformed 75\% and 100\% of its component models in 30 and 26 countries respectively.

\begin{table}

\caption{\label{tab:ensembles}Predictive performance of main ensembles, as measured by the scaled relative WIS.}
\centering
\begin{tabular}[t]{lrrrr}
\toprule
Horizon & Weighted mean & Weighted median & Unweighted mean & Unweighted median\\
\midrule
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{Cases}}\\
\hspace{1em}\cellcolor{gray!6}{1 week} & \cellcolor{gray!6}{0.59} & \cellcolor{gray!6}{0.62} & \cellcolor{gray!6}{0.59} & \cellcolor{gray!6}{0.61}\\
\hspace{1em}2 weeks & 0.67 & 0.67 & 0.67 & 0.67\\
\hspace{1em}\cellcolor{gray!6}{3 weeks} & \cellcolor{gray!6}{0.79} & \cellcolor{gray!6}{0.70} & \cellcolor{gray!6}{0.81} & \cellcolor{gray!6}{0.71}\\
\hspace{1em}4 weeks & 1.06 & 0.75 & 1.09 & 0.79\\
\addlinespace[0.3em]
\multicolumn{5}{l}{\textbf{Deaths}}\\
\hspace{1em}\cellcolor{gray!6}{1 week} & \cellcolor{gray!6}{0.63} & \cellcolor{gray!6}{0.59} & \cellcolor{gray!6}{1.00} & \cellcolor{gray!6}{0.59}\\
\hspace{1em}2 weeks & 0.57 & 0.54 & 0.81 & 0.53\\
\hspace{1em}\cellcolor{gray!6}{3 weeks} & \cellcolor{gray!6}{0.64} & \cellcolor{gray!6}{0.56} & \cellcolor{gray!6}{0.83} & \cellcolor{gray!6}{0.54}\\
\hspace{1em}4 weeks & 0.83 & 0.64 & 0.82 & 0.62\\
\bottomrule
\end{tabular}
\end{table}

We considered alternative methods for creating ensembles from the participating forecasts, using either a mean or median to combine either weighted or unweighted forecasts (Table \ref{tab:ensembles}). Across locations we observed that the median outperformed the mean across all one through four week horizons and both cases and death targets, for all but cases at the 1 week horizon. This held regardless of whether the component forecasts were weighted or unweighted by their individual past performance. Between methods of combination, weighting made little difference to the performance of the median ensemble, but \DIFdelbegin \DIFdel{slightly improved performance of the mean ensemble }\DIFdelend \DIFaddbegin \DIFadd{appeared to improve performance of a mean ensemble in forecasting deaths}\DIFaddend .

\hypertarget{discussion}{%
\section{Discussion}\label{discussion}}

We collated 12 months of forecasts of COVID-19 cases and deaths across 32 countries in Europe, collecting from multiple independent teams and using a principled approach to standardising both forecast targets and the predictive distribution of forecasts. We combined these into an ensemble forecast and compared the relative performance of forecasts between models, finding that the ensemble forecasts outperformed most individual models across all countries and horizons over time.

Across all models we observed that forecasting changes in trend in real time was particularly challenging. Our study period included multiple fundamental changes in viral-, individual-, and population-level factors driving the transmission of COVID-19 across Europe. In early 2021, the introduction of vaccination started to change population-level associations between infections, cases, and deaths \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-europeancentrefordiseasepreventionandcontrolInterimGuidanceBenefits2021}{{[}36{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-europeancentrefordiseasepreventionandcontrolInterimGuidanceBenefits2021}{{[}41{]}}\DIFaddend , while the Delta variant emerged and became dominant \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-europeancentrefordiseasepreventionandcontrolThreatAssessmentBrief2021}{{[}37{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-europeancentrefordiseasepreventionandcontrolThreatAssessmentBrief2021}{{[}42{]}}\DIFaddend . Similarly from late 2021 we saw the interaction of individually waning immunity during the emergence and global spread of the Omicron variant \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-europeancentrefordiseasepreventionandcontrolAssessmentFurtherSpread2022}{{[}38{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-europeancentrefordiseasepreventionandcontrolAssessmentFurtherSpread2022}{{[}43{]}}\DIFaddend . Neither the extent nor timing of these factors were uniform across European countries covered by the Forecast Hub \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-europeancentrefordiseasepreventionandcontrolOverviewImplementationCOVID192021}{{[}39{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-europeancentrefordiseasepreventionandcontrolOverviewImplementationCOVID192021}{{[}44{]}}\DIFaddend . This meant that the performance of any single forecasting model depended partly on the ability, speed, and precision with which it could adapt to new conditions for each forecast target.

We observed a contrast between a more stable performance of forecasting deaths further into the future compared to forecasts of cases. Previous work has found rapidly declining performance for case forecasts with increasing horizon \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-cramerEvaluationIndividualEnsemble2021}{{[}31{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-cramerEvaluationIndividualEnsemble2021}{{[}36{]}}\DIFaddend , \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-castroTurningPointEnd2020}{{[}40{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-castroTurningPointEnd2020}{{[}45{]}}\DIFaddend , while death forecasts can perform well with up to six weeks lead time \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-friedmanPredictivePerformanceInternational2021}{{[}41{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-friedmanPredictivePerformanceInternational2021}{{[}46{]}}\DIFaddend . We can \DIFdelbegin \DIFdel{similarly }\DIFdelend link this to the specific epidemic dynamics in this study.
\DIFaddbegin 

\DIFadd{First, }\DIFaddend COVID-19 has a typical serial interval of less than a week \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-aleneSerialIntervalIncubation2021}{{[}42{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-aleneSerialIntervalIncubation2021}{{[}47{]}}\DIFaddend . This implies that case forecasts of more than two weeks only remain valid if rates of \DIFaddbegin \DIFadd{both }\DIFaddend transmission and detection remain stable over the entire forecast horizon. \DIFdelbegin \DIFdel{This is unlikely to have held given the }\DIFdelend \DIFaddbegin \DIFadd{In contrast, we saw }\DIFaddend rapid changes in epidemic dynamics across many countries in Europe \DIFdelbegin \DIFdel{. Meanwhile}\DIFdelend \DIFaddbegin \DIFadd{over our study period, impacting the longer term case forecasts.
}

\DIFadd{Second}\DIFaddend , we can interpret the higher reliability of death forecasts as due to the \DIFdelbegin \DIFdel{longer time lag between infection and death }\DIFdelend \DIFaddbegin \DIFadd{different lengths and distributions of time lags from infection to case and death reporting }\DIFaddend \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-jinLagDailyReported2021}{{[}43{]}}%%%
\DIFdel{, and higher consistency of reportingdeaths in surveillance data }\DIFdelend \DIFaddbegin \hyperlink{ref-jinLagDailyReported2021}{{[}48{]}}\DIFadd{. For example, a spike in infections may be matched by a consistently sharp increase in case reporting, but a longer-tailed distribution of the subsequent increase in death reports. This creates a lower magnitude of fluctuation in the time-series of deaths compared to that of cases. Similarly, surveillance data for death reporting is substantially more consistent, with fewer errors and retrospective corrections, than case reporting }\DIFaddend \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-catalaRobustEstimationDiagnostic2021}{{[}44{]}}%%%
\DIFdel{. This allows forecasters to incorporate the effect of changes in transmission. Additionally, }\DIFdelend \DIFaddbegin \hyperlink{ref-catalaRobustEstimationDiagnostic2021}{{[}49{]}}\DIFadd{.
}

\DIFadd{Third, we also note that }\DIFaddend the performance of trend-based forecasts may have benefited from the slower changes to trends in incident deaths caused by gradually increasing vaccination rates. \DIFaddbegin \DIFadd{These features allow forecasters to incorporate the effect of changes in transmission more easily when forecasting deaths, compared to cases.
}\DIFaddend 

We found the ensemble in this study continued to outperform both other models and the baseline at up to four weeks ahead. Our results support previous findings that ensemble forecasts are the best or nearly the best performing models with respect to absolute predictive performance and appropriate coverage of uncertainty \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-funkShorttermForecastsInform2020}{{[}12{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-funkShorttermForecastsInform2020}{{[}16{]}}\DIFaddend , \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-viboudRAPIDDEbolaForecasting2018}{{[}14{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-viboudRAPIDDEbolaForecasting2018}{{[}18{]}}\DIFaddend , \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-cramerEvaluationIndividualEnsemble2021}{{[}31{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-cramerEvaluationIndividualEnsemble2021}{{[}36{]}}\DIFaddend . While the ensemble was consistently high performing, it was not strictly dominant across all forecast targets, reflecting findings from previous comparable studies of COVID-19 forecasts \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-bracherPreregisteredShorttermForecasting2021}{{[}11{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-bracherPreregisteredShorttermForecasting2021}{{[}15{]}}\DIFaddend , \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-brooksComparingEnsembleApproaches2020}{{[}45{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-brooksComparingEnsembleApproaches2020}{{[}50{]}}\DIFaddend . Our finding suggests the usefulness of an ensemble as a robust summary when forecasting across many spatio-temporal targets, without replacing the importance of communicating the full range of model predictions.

When exploring variations in ensemble methods, we found that the choice of median over means yielded the most consistent improvement in predictive performance, regardless of the method of weighting. Other work has supported the importance of the median in providing a stable forecast that better accounts for outlier forecasts than the mean \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-brooksComparingEnsembleApproaches2020}{{[}45{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-brooksComparingEnsembleApproaches2020}{{[}50{]}}\DIFaddend , although this finding may be dependent on the quality of the individual forecast submissions. In contrast, weighing models by past performance did not result in any consistent improvement in performance. This is in line with existing mixed evidence for any optimal ensemble method for combining short term probabilistic infectious disease forecasts. Many methods of combination have performed competitively in analyses of forecasts for COVID-19 in the US, including the simple mean and weighted approaches outperforming unweighted or median methods \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-taylorCombiningProbabilisticForecasts2021}{{[}33{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-taylorCombiningProbabilisticForecasts2021}{{[}38{]}}\DIFaddend . This contrasts with later analyses finding weighted methods to give similar performance to a median average \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-rayEnsembleForecastsCoronavirus2020e}{{[}10{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-rayEnsembleForecastsCoronavirus2020e}{{[}14{]}}\DIFaddend , \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-brooksComparingEnsembleApproaches2020}{{[}45{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-brooksComparingEnsembleApproaches2020}{{[}50{]}}\DIFaddend . We can partly explain this inconsistency if performance of each method depends on the outcome being predicted (cases, deaths), its count (incident, cumulative) and absolute level, the changing disease dynamics, and the varying quality and quantity of forecasting teams over time.

We note several limitations in our approach to assessing the relative performance of an ensemble among forecast models. \DIFaddbegin \DIFadd{While we have described differences in model scores, we have not used any formal statistical test for comparing forecast scores, such as the Diebold-Mariano test }\protect\hyperlink{ref-dieboldComparingPredictiveAccuracy1995}{{[}51{]}}\DIFadd{, recognising that it is unclear how this is best achieved across many models. }\DIFaddend Our results are the outcome of evaluating forecasts against a specific performance metric and baseline, where multiple options for evaluation exist and the choice reflects the aim of the evaluation process. Further, our choice of baseline model affects the given performance scores in absolute terms, and more generally the choice of appropriate baseline for epidemic forecast models is not obvious when assessing infectious disease forecasts. The model used here is supported by previous work \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-cramerEvaluationIndividualEnsemble2021}{{[}31{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-cramerEvaluationIndividualEnsemble2021}{{[}36{]}}\DIFaddend , yet previous evaluation in a similar context has suggested that choice of baseline affects relative performance in general \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-bracherNationalSubnationalShortterm2021}{{[}46{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-bracherNationalSubnationalShortterm2021}{{[}52{]}}\DIFaddend , and future research should be done on the best choices of baseline models in the context of infectious disease epidemics.

Our assessment of forecast performance may further have been inaccurate due to limitations in the observed data against which we evaluated forecasts. We sourced data from a globally aggregated database to maintain compatibility across 32 countries \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-dongInteractiveWebbasedDashboard2020}{{[}21{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-dongInteractiveWebbasedDashboard2020}{{[}25{]}}\DIFaddend . However, this made it difficult to identify the origin of lags and inconsistencies between national data streams, and to what extent these could bias forecasts for different targets. In particular we saw some real time data revised retrospectively, introducing bias in either direction where the data used to create forecasts was not the same as that used to evaluate it. We attempted to mitigate this by using an automated process for determining data revisions, and excluding forecasts made at a time of missing, unreliable, or heavily revised data. \DIFaddbegin \DIFadd{We also recognise that evaluating forecasts against updated data is a valid alternative approach used elsewhere }\protect\hyperlink{ref-cramerEvaluationIndividualEnsemble2021}{{[}36{]}}\DIFadd{. }\DIFaddend More generally it is unclear if the expectation of observation revisions should be a feature built into forecasts. Further research is needed to understand the perspective of end-users of forecasts in order to assess this.

\DIFaddbegin \DIFadd{The focus of this study was describing and summarising an ensemble of many models. We note that we have little insight into the individual methods and wide variety of assumptions that modellers used. While we asked modellers to provide a short description of their methods, we did not create a rigorous framework for this, and we did not document whether modellers changed the methods for a particular submitted model over time. Both the content of and variation in modelling methods and assumptions are likely to be critical to explaining performance, rather than describing or summarising it. Exploring modellers' methods and relating this to forecast performance will be an important area of future work.
}

\DIFaddend In an emergency setting, \DIFdelbegin \DIFdel{open }\DIFdelend access to visualised forecasts and underlying data is useful for researchers, policymakers, and the public \DIFdelbegin \DIFdel{. For forecast producers, an easily accessible comparison between results from different methods can highlight individual strengths and weaknesses and help prioritise new areas of work. For forecast users, probabilistic information about the future can influence decisions in the present that can then change epidemic dynamics }\DIFdelend \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-basshuysenThreeWaysWhich2021}{{[}1{]}}%%%
\DIFdel{. }%DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdel{Existing participatory modelling efforts for }\DIFdelend \DIFaddbegin \hyperlink{ref-cdcCoronavirusDisease20192020}{{[}2{]}}\DIFadd{. Previous European multi-country efforts to forecast }\DIFaddend COVID-19 have \DIFdelbegin \DIFdel{been useful for policy communication }%DIFDELCMD < \protect\hyperlink{ref-cdcCoronavirusDisease20192020}{{[}2{]}}%%%
\DIFdel{, while multi-country efforts have }\DIFdelend included only single models adapted to country-specific parameters \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-aguasModellingCOVID19Pandemic2020}{{[}47{]}}%%%
\DIFdel{--}\DIFdelend \DIFaddbegin \hyperlink{ref-aguasModellingCOVID19Pandemic2020}{{[}6{]}}\DIFadd{, }\DIFaddend \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-agostoMonitoringCOVID19Contagion2021}{{[}49{]}}%%%
\DIFdel{.
By expanding }\DIFdelend \DIFaddbegin \hyperlink{ref-adibParticipatoryModellingApproach2021}{{[}7{]}}\DIFadd{, }\protect\hyperlink{ref-agostoMonitoringCOVID19Contagion2021}{{[}9{]}}\DIFadd{.
}

\DIFadd{The European Forecasting Hub acted as a unique tool for creating an open-access, cross-country modelling network, and connecting this to public health policy across Europe. By opening }\DIFaddend participation to many modelling teams \DIFdelbegin \DIFdel{, our work was }\DIFdelend \DIFaddbegin \DIFadd{and with international high participation, we were }\DIFaddend able to create robust ensemble forecasts across Europe\DIFdelbegin \DIFdel{while allowing }\DIFdelend \DIFaddbegin \DIFadd{. This also allows }\DIFaddend comparison across forecasts built with different interpretations of current data, on a like for like scale in real time. \DIFdelbegin \DIFdel{At the same time, collating }\DIFdelend \DIFaddbegin \DIFadd{The European Hub has supported policy outputs at an international, regional, and national level, including Hub forecasts cited weekly in ECDC Communicable Disease Threats Reports (}\protect\hyperlink{ref-europeancentrefordiseasepreventionandcontrolWeeklyThreatsReports}{{[}53{]}}\DIFadd{).
}

\DIFadd{For forecast producers, an easily accessible comparison between results from different methods can highlight individual strengths and weaknesses and help prioritise new areas of work. Collating }\DIFaddend time-stamped predictions ensures that we can test true out-of-sample performance of models and avoid retrospective claims of performance. Testing the limits of forecasting ability with these comparisons forms an important part of communicating any model-based prediction to decision makers. \DIFaddbegin \DIFadd{For example, the weekly ECDC Communicable Disease Threats reports include the specific results of this work by qualitatively highlighting the greater uncertainty around case forecasts compared to death forecasts.
}\DIFaddend 

This study raises many further questions which could inform epidemic forecast modellers and users. The dataset created by the European Forecast Hub is an openly accessible, standardised, and extensively documented catalogue of real time forecasting work from a range of teams and models across Europe \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-europeancovid-19forecasthubEuropeanCovid19Forecast}{{[}24{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-europeancovid-19forecasthubEuropeanCovid19Forecast}{{[}28{]}}\DIFaddend , and we recommend its use for further research on forecast performance. In the code developed for this study we provide a worked example of downloading and using both the forecasts and their evaluation scores \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-PredictivePerformanceMultimodel2022}{{[}27{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-PredictivePerformanceMultimodel2022}{{[}32{]}}\DIFaddend .

Future work could explore the impact on forecast models of changing epidemiology at a broad spatial scale by combining analyses of trends and turning points in cases and deaths with forecast performance, or extending to include data on vaccination, variant, or policy changes over time. There is also much scope for future research into methods for combining forecasts to improve performance of an ensemble. This includes altering the inclusion criteria of forecast models based on different thresholds of past performance, excluding or including only forecasts that predict the lowest and highest values (trimming) \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-taylorCombiningProbabilisticForecasts2021}{{[}33{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-taylorCombiningProbabilisticForecasts2021}{{[}38{]}}\DIFaddend , or using alternative weighting methods such as quantile regression averaging \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-funkShorttermForecastsInform2020}{{[}12{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-funkShorttermForecastsInform2020}{{[}16{]}}\DIFaddend . Exploring these questions would add to our understanding of real time performance, supporting and improving future forecasting efforts.

We see additional scope to adapt the Hub format to the changing COVID-19 situation across Europe. We have extended the Forecast Hub infrastructure to include short term forecasts for hospitalisations with COVID-19, which is a challenging task due to limited data across the locations covered by the hub. As the policy focus shifts from immediate response to anticipating changes brought by vaccinations or the geographic spread of new variants \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-europeancentrefordiseasepreventionandcontrolOverviewImplementationCOVID192021}{{[}39{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-europeancentrefordiseasepreventionandcontrolOverviewImplementationCOVID192021}{{[}44{]}}\DIFaddend , we are also separately investigating models for longer term scenarios in addition to the short term forecasts in a similar framework to existing scenario modelling work in the US \protect\DIFdelbegin %DIFDELCMD < \hyperlink{ref-borcheringModelingFutureCOVID192021}{{[}50{]}}%%%
\DIFdelend \DIFaddbegin \hyperlink{ref-borcheringModelingFutureCOVID192021}{{[}54{]}}\DIFaddend .

In conclusion, we have shown that during a rapidly evolving epidemic spreading through multiple populations, an ensemble forecast performed highly consistently across a large matrix of forecast targets, typically outperforming the majority of its separate component models and a naive baseline model. In addition, we have linked issues with the predictability of short-term case forecasts to underlying COVID-19 epidemiology, and shown that ensemble methods based on past model performance were unable to reliably improve forecast performance. Our work constitutes a step towards both unifying COVID-19 forecasts and improving our understanding of them.

\hypertarget{references}{%
\section{References}\label{references}}

\hypertarget{refs}{}
\begin{CSLReferences}{0}{0}
\leavevmode\vadjust pre{\hypertarget{ref-basshuysenThreeWaysWhich2021}{}}%
\CSLLeftMargin{{[}1{]} }
\CSLRightInline{P. van Basshuysen, L. White, D. Khosrowi, and M. Frisch, {``Three {Ways} in {Which Pandemic Models May Perform} a {Pandemic},''} \emph{Erasmus Journal for Philosophy and Economics}, vol. 14, no. 1, 1, pp. 110-127-110-127, Jul. 2021, doi: \href{https://doi.org/10.23941/ejpe.v14i1.582}{10.23941/ejpe.v14i1.582}.}

\leavevmode\vadjust pre{\hypertarget{ref-cdcCoronavirusDisease20192020}{}}%
\CSLLeftMargin{{[}2{]} }
\CSLRightInline{CDC, {``Coronavirus {Disease} 2019 ({COVID-19}),''} Feb. 11, 2020. \url{https://www.cdc.gov/coronavirus/2019-ncov/science/forecasting/forecasting.html} (accessed Jan. 09, 2022).}

\leavevmode\vadjust pre{\hypertarget{ref-europeancentrefordiseasepreventionandcontrolForecastingCOVID19Cases2021}{}}%
\CSLLeftMargin{{[}3{]} }
\CSLRightInline{European Centre for Disease Prevention and Control, {``Forecasting {COVID-19} cases and deaths in {Europe} - new hub will support {European} pandemic planning,''} Apr. 22, 2021. \url{https://www.ecdc.europa.eu/en/news-events/forecasting-covid-19-cases-and-deaths-europe-new-hub}}

\leavevmode\vadjust pre{\hypertarget{ref-zelnerAccountingUncertaintyPandemic2021}{}}%
\CSLLeftMargin{{[}4{]} }
\CSLRightInline{J. Zelner, J. Riou, R. Etzioni, and A. Gelman, {``Accounting for uncertainty during a pandemic,''} \emph{PATTER}, vol. 2, no. 8, Aug. 2021, doi: \href{https://doi.org/10.1016/j.patter.2021.100310}{10.1016/j.patter.2021.100310}.}

\leavevmode\vadjust pre{\hypertarget{ref-jamesUseMisuseMathematical2021}{}}%
\CSLLeftMargin{{[}5{]} }
\CSLRightInline{L. P. James, J. A. Salomon, C. O. Buckee, and N. A. Menzies, {``The {Use} and {Misuse} of {Mathematical Modeling} for {Infectious Disease Policymaking}: {Lessons} for the {COVID-19 Pandemic},''} \emph{Med Decis Making}, vol. 41, no. 4, pp. 379--385, May 2021, doi: \href{https://doi.org/10.1177/0272989X21990391}{10.1177/0272989X21990391}.}

\leavevmode\vadjust pre{\DIFdelbegin %DIFDELCMD < \hypertarget{ref-reichCollaborativeMultiyearMultimodel2019}{}%%%
\DIFdelend \DIFaddbegin \hypertarget{ref-aguasModellingCOVID19Pandemic2020}{}\DIFaddend }%
\CSLLeftMargin{{[}6{]} }
\DIFaddbegin \CSLRightInline{R. Aguas \emph{et al.}, {``Modelling the {COVID-19} pandemic in context: An international participatory approach,''} \emph{BMJ Global Health}, vol. 5, no. 12, p. e003126, Dec. 2020, doi: \href{https://doi.org/10.1136/bmjgh-2020-003126}{10.1136/bmjgh-2020-003126}.}

\leavevmode\vadjust \DIFadd{pre}{\hypertarget{ref-adibParticipatoryModellingApproach2021}{}}%DIF > 
\CSLLeftMargin{{[}7{]} }
\CSLRightInline{K. Adib \emph{et al.}, {``A participatory modelling approach for investigating the spread of {COVID-19} in countries of the {Eastern Mediterranean Region} to support public health decision-making,''} \emph{BMJ Global Health}, vol. 6, no. 3, p. e005207, Mar. 2021, doi: \href{https://doi.org/10.1136/bmjgh-2021-005207}{10.1136/bmjgh-2021-005207}.}

\leavevmode\vadjust \DIFadd{pre}{\hypertarget{ref-Agosto2020}{}}%DIF > 
\CSLLeftMargin{{[}8{]} }
\CSLRightInline{A. Agosto and P. Giudici, {``A poisson autoregressive model to understand COVID-19 contagion dynamics,''} \emph{Risks}, vol. 8, no. 3, p. 77, Jul. 2020, doi: \href{https://doi.org/10.3390/risks8030077}{10.3390/risks8030077}.}

\leavevmode\vadjust \DIFadd{pre}{\hypertarget{ref-agostoMonitoringCOVID19Contagion2021}{}}%DIF > 
\CSLLeftMargin{{[}9{]} }
\CSLRightInline{A. Agosto, A. Campmas, P. Giudici, and A. Renda, {``Monitoring {COVID-19} contagion growth,''} \emph{Statistics in Medicine}, vol. 40, no. 18, pp. 4150--4160, 2021, doi: \href{https://doi.org/10.1002/sim.9020}{10.1002/sim.9020}.}

\leavevmode\vadjust \DIFadd{pre}{\hypertarget{ref-reichCollaborativeMultiyearMultimodel2019}{}}%DIF > 
\CSLLeftMargin{{[}10{]} }
\DIFaddend \CSLRightInline{N. G. Reich \emph{et al.}, {``A collaborative multiyear, multimodel assessment of seasonal influenza forecasting in the {United States},''} \emph{PNAS}, vol. 116, no. 8, pp. 3146--3154, Feb. 2019, doi: \href{https://doi.org/10.1073/pnas.1812594116}{10.1073/pnas.1812594116}.}

\leavevmode\vadjust pre{\hypertarget{ref-johanssonOpenChallengeAdvance2019}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}7{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}11{]} }
\DIFaddend \CSLRightInline{M. A. Johansson \emph{et al.}, {``An open challenge to advance probabilistic forecasting for dengue epidemics,''} \emph{PNAS}, vol. 116, no. 48, pp. 24268--24274, Nov. 2019, doi: \href{https://doi.org/10.1073/pnas.1909865116}{10.1073/pnas.1909865116}.}

\leavevmode\vadjust pre{\hypertarget{ref-reichAccuracyRealtimeMultimodel2019}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}8{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}12{]} }
\DIFaddend \CSLRightInline{N. G. Reich \emph{et al.}, {``Accuracy of real-time multi-model ensemble forecasts for seasonal influenza in the {U}.{S},''} \emph{PLoS Comput Biol}, vol. 15, no. 11, p. e1007486, Nov. 2019, doi: \href{https://doi.org/10.1371/journal.pcbi.1007486}{10.1371/journal.pcbi.1007486}.}

\leavevmode\vadjust pre{\hypertarget{ref-cramerUnitedStatesCOVID192021}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}9{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}13{]} }
\DIFaddend \CSLRightInline{E. Y. Cramer \emph{et al.}, {``The {United States COVID-19 Forecast Hub} dataset,''} p. 2021.11.04.21265886, Nov. 2021, doi: \href{https://doi.org/10.1101/2021.11.04.21265886}{10.1101/2021.11.04.21265886}.}

\leavevmode\vadjust pre{\hypertarget{ref-rayEnsembleForecastsCoronavirus2020e}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}10{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}14{]} }
\DIFaddend \CSLRightInline{E. L. Ray \emph{et al.}, {``Ensemble {Forecasts} of {Coronavirus Disease} 2019 ({COVID-19}) in the {U}.{S}.''} p. 2020.08.19.20177493, Aug. 2020, doi: \href{https://doi.org/10.1101/2020.08.19.20177493}{10.1101/2020.08.19.20177493}.}

\leavevmode\vadjust pre{\hypertarget{ref-bracherPreregisteredShorttermForecasting2021}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}11{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}15{]} }
\DIFaddend \CSLRightInline{J. Bracher \emph{et al.}, {``A pre-registered short-term forecasting study of {COVID-19} in {Germany} and {Poland} during the second wave,''} \emph{Nat Commun}, vol. 12, no. 1, 1, p. 5173, Aug. 2021, doi: \href{https://doi.org/10.1038/s41467-021-25207-0}{10.1038/s41467-021-25207-0}.}

\leavevmode\vadjust pre{\hypertarget{ref-funkShorttermForecastsInform2020}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}12{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}16{]} }
\DIFaddend \CSLRightInline{S. Funk \emph{et al.}, {``Short-term forecasts to inform the response to the {Covid-19} epidemic in the {UK},''} \emph{medRxiv}, p. 2020.11.11.20220962, Nov. 2020, doi: \href{https://doi.org/10.1101/2020.11.11.20220962}{10.1101/2020.11.11.20220962}.}

\leavevmode\vadjust pre{\hypertarget{ref-bicherSupportingCOVID19PolicyMaking2021}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}13{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}17{]} }
\DIFaddend \CSLRightInline{M. Bicher \emph{et al.}, {``Supporting {COVID-19 Policy-Making} with a {Predictive Epidemiological Multi-Model Warning System},''} \emph{medRxiv}, p. 2020.10.18.20214767, Apr. 2021, doi: \href{https://doi.org/10.1101/2020.10.18.20214767}{10.1101/2020.10.18.20214767}.}

\leavevmode\vadjust pre{\hypertarget{ref-viboudRAPIDDEbolaForecasting2018}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}14{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}18{]} }
\DIFaddend \CSLRightInline{C. Viboud \emph{et al.}, {``The {RAPIDD} ebola forecasting challenge: {Synthesis} and lessons learnt,''} \emph{Epidemics}, vol. 22, pp. 13--21, Mar. 2018, doi: \href{https://doi.org/10.1016/j.epidem.2017.08.002}{10.1016/j.epidem.2017.08.002}.}

\leavevmode\vadjust pre{\hypertarget{ref-buizzaIntroductionSpecialIssue2019}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}15{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}19{]} }
\DIFaddend \CSLRightInline{R. Buizza, {``Introduction to the special issue on {`25 years of ensemble forecasting'},''} \emph{Quarterly Journal of the Royal Meteorological Society}, vol. 145, no. S1, pp. 1--11, 2019, doi: \href{https://doi.org/10.1002/qj.3370}{10.1002/qj.3370}.}

\leavevmode\vadjust pre{\hypertarget{ref-moranEpidemicForecastingMessier2016}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}16{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}20{]} }
\DIFaddend \CSLRightInline{K. R. Moran \emph{et al.}, {``Epidemic {Forecasting} is {Messier Than Weather Forecasting}: {The Role} of {Human Behavior} and {Internet Data Streams} in {Epidemic Forecast},''} \emph{J Infect Dis}, vol. 214, pp. S404--S408, Dec. 2016, doi: \href{https://doi.org/10.1093/infdis/jiw375}{10.1093/infdis/jiw375}.}

\leavevmode\vadjust pre{\hypertarget{ref-europeancovid-19forecasthubEuropeanCOVID19Forecast2021}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}17{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}21{]} }
\DIFaddend \CSLRightInline{European Covid-19 Forecast Hub, \emph{European {COVID-19 Forecast Hub}}. {covid19-forecast-hub-europe}, 2021.Available: \url{https://github.com/covid19-forecast-hub-europe/covid19-forecast-hub-europe}}

\leavevmode\vadjust pre{\hypertarget{ref-cramerReichlabCovid19forecasthubRelease2021}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}18{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}22{]} }
\DIFaddend \CSLRightInline{E. Cramer \emph{et al.}, {``Reichlab/Covid19-forecast-hub: Release for {Zenodo}, 20210816,''} Aug. 2021, doi: \href{https://doi.org/10.5281/zenodo.5208210}{10.5281/zenodo.5208210}.}

\leavevmode\vadjust pre{\hypertarget{ref-wangReichlabCovidHubUtilsRepository2021}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}19{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}23{]} }
\DIFaddend \CSLRightInline{S. Y. Wang \emph{et al.}, {``Reichlab/{covidHubUtils}: Repository release for {Zenodo},''} Aug. 2021, doi: \href{https://doi.org/10.5281/zenodo.5207940}{10.5281/zenodo.5207940}.}

\leavevmode\vadjust pre{\hypertarget{ref-bracherGermanPolishCOVID192020}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}20{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}24{]} }
\DIFaddend \CSLRightInline{J. Bracher \emph{et al.}, \emph{The {German} and {Polish COVID-19 Forecast Hub}}. 2020.Available: \url{https://github.com/KITmetricslab/covid19-forecast-hub-de}}

\leavevmode\vadjust pre{\hypertarget{ref-dongInteractiveWebbasedDashboard2020}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}21{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}25{]} }
\DIFaddend \CSLRightInline{E. Dong, H. Du, and L. Gardner, {``An interactive web-based dashboard to track {COVID-19} in real time,''} \emph{The Lancet Infectious Diseases}, vol. 20, no. 5, pp. 533--534, May 2020, doi: \href{https://doi.org/10.1016/S1473-3099(20)30120-1}{10.1016/S1473-3099(20)30120-1}.}

\leavevmode\vadjust pre{\hypertarget{ref-europeancovid-19forecasthubCommunity}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}22{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}26{]} }
\DIFaddend \CSLRightInline{European Covid-19 Forecast Hub, {``Community.''} \url{https://covid19forecasthub.eu/community.html}}

\leavevmode\vadjust pre{\hypertarget{ref-europeancovid-19forecasthubCovid19forecasthubeuropeWiki}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}23{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}27{]} }
\DIFaddend \CSLRightInline{European Covid-19 Forecast Hub, {``Covid19-forecast-hub-europe: {Wiki}.''} \url{https://github.com/covid19-forecast-hub-europe/covid19-forecast-hub-europe}}

\leavevmode\vadjust pre{\hypertarget{ref-europeancovid-19forecasthubEuropeanCovid19Forecast}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}24{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}28{]} }
\DIFaddend \CSLRightInline{European Covid-19 Forecast Hub, {``European {Covid-19 Forecast Hub}.''} \url{https://covid19forecasthub.eu/index.html}}

\leavevmode\vadjust pre{\DIFaddbegin \hypertarget{ref-katharine_sherratt_2022_7356267}{}}%DIF > 
\CSLLeftMargin{{[}29{]} }
\CSLRightInline{K. Sherratt \emph{et al.}, {``European covid-19 forecast hub.''} Zenodo, Nov. 2022. doi: \href{https://doi.org/10.5281/zenodo.7356267}{10.5281/zenodo.7356267}.}

\leavevmode\vadjust \DIFadd{pre}{\DIFaddend \hypertarget{ref-epiforecastsProjectECDCEuropean2021}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}25{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}30{]} }
\DIFaddend \CSLRightInline{EpiForecasts, {``Project: {ECDC European COVID-19 Forecast Hub} - {Zoltar},''} 2021. \url{https://www.zoltardata.com/project/238}}

\leavevmode\vadjust pre{\hypertarget{ref-reichZoltarForecastArchive2021}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}26{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}31{]} }
\DIFaddend \CSLRightInline{N. G. Reich, M. Cornell, E. L. Ray, K. House, and K. Le, {``The {Zoltar} forecast archive, a tool to standardize and store interdisciplinary prediction research,''} \emph{Sci Data}, vol. 8, no. 1, 1, p. 59, Feb. 2021, doi: \href{https://doi.org/10.1038/s41597-021-00839-5}{10.1038/s41597-021-00839-5}.}

\leavevmode\vadjust pre{\hypertarget{ref-PredictivePerformanceMultimodel2022}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}27{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}32{]} }
\DIFaddend \CSLRightInline{\emph{Predictive performance of multi-model ensemble forecasts of {Covid-19} across {European} nations}. {covid19-forecast-hub-europe}, 2022.Available: \url{https://github.com/covid19-forecast-hub-europe/euro-hub-ensemble}}

\leavevmode\vadjust pre{\hypertarget{ref-nikosibosseScoringutilsUtilitiesScoring2020}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}28{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}33{]} }
\DIFaddend \CSLRightInline{Nikos I Bosse, Hugo Gruson, Sebastian Funk, EpiForecasts, and Sam Abbott, \emph{Scoringutils: {Utilities} for {Scoring} and {Assessing Predictions}}. 2020.Available: \url{https://github.com/epiforecasts/scoringutils}}

\leavevmode\vadjust pre{\hypertarget{ref-bracherEvaluatingEpidemicForecasts2021}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}29{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}34{]} }
\DIFaddend \CSLRightInline{J. Bracher, E. L. Ray, T. Gneiting, and N. G. Reich, {``Evaluating epidemic forecasts in an interval format,''} \emph{PLOS Computational Biology}, vol. 17, no. 2, p. e1008618, Feb. 2021, doi: \href{https://doi.org/10.1371/journal.pcbi.1008618}{10.1371/journal.pcbi.1008618}.}

\leavevmode\vadjust pre{\hypertarget{ref-gneitingStrictlyProperScoring2007}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}30{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}35{]} }
\DIFaddend \CSLRightInline{T. Gneiting and A. E. Raftery, {``Strictly {Proper Scoring Rules}, {Prediction}, and {Estimation},''} \emph{Journal of the American Statistical Association}, vol. 102, no. 477, pp. 359--378, Mar. 2007, doi: \href{https://doi.org/10.1198/016214506000001437}{10.1198/016214506000001437}.}

\leavevmode\vadjust pre{\hypertarget{ref-cramerEvaluationIndividualEnsemble2021}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}31{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}36{]} }
\DIFaddend \CSLRightInline{E. Y. Cramer \emph{et al.}, {``Evaluation of individual and ensemble probabilistic forecasts of {COVID-19} mortality in the {US},''} \emph{medRxiv}, p. 2021.02.03.21250974, Jan. 2021, doi: \href{https://doi.org/10.1101/2021.02.03.21250974}{10.1101/2021.02.03.21250974}.}

\leavevmode\vadjust pre{\hypertarget{ref-genestVincentizationRevisited1992}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}32{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}37{]} }
\DIFaddend \CSLRightInline{C. Genest, {``Vincentization {Revisited},''} \emph{The Annals of Statistics}, vol. 20, no. 2, pp. 1137--1142, 1992,Available: \url{https://www.jstor.org/stable/2242003}}

\leavevmode\vadjust pre{\hypertarget{ref-taylorCombiningProbabilisticForecasts2021}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}33{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}38{]} }
\DIFaddend \CSLRightInline{J. W. Taylor and K. S. Taylor, {``Combining {Probabilistic Forecasts} of {COVID-19 Mortality} in the {United States},''} \emph{Eur J Oper Res}, Jun. 2021, doi: \href{https://doi.org/10.1016/j.ejor.2021.06.044}{10.1016/j.ejor.2021.06.044}.}

\leavevmode\vadjust pre{\hypertarget{ref-rayComparingTrainedUntrained2022}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}34{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}39{]} }
\DIFaddend \CSLRightInline{E. L. Ray \emph{et al.}, {``Comparing trained and untrained probabilistic ensemble forecasts of {COVID-19} cases and deaths in the {United States},''} Jan. 28, 2022. Accessed: Mar. 30, 2022. {[}Online{]}. Available: \url{http://arxiv.org/abs/2201.12387}}

\leavevmode\vadjust pre{\hypertarget{ref-harrellNewDistributionfreeQuantile1982}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}35{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}40{]} }
\DIFaddend \CSLRightInline{F. E. HARRELL and C. E. DAVIS, {``A new distribution-free quantile estimator,''} \emph{Biometrika}, vol. 69, no. 3, pp. 635--640, Dec. 1982, doi: \href{https://doi.org/10.1093/biomet/69.3.635}{10.1093/biomet/69.3.635}.}

\leavevmode\vadjust pre{\hypertarget{ref-europeancentrefordiseasepreventionandcontrolInterimGuidanceBenefits2021}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}36{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}41{]} }
\DIFaddend \CSLRightInline{European Centre for Disease Prevention and Control, {``Interim guidance on the benefits of full vaccination against {COVID-19} for transmission and implications for non-pharmaceutical interventions - 21 {April} 2021,''} {ECDC}, {Stockholm}, 2021.Available: \url{https://www.ecdc.europa.eu/en/publications-data/interim-guidance-benefits-full-vaccination-against-covid-19-transmission}}

\leavevmode\vadjust pre{\hypertarget{ref-europeancentrefordiseasepreventionandcontrolThreatAssessmentBrief2021}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}37{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}42{]} }
\DIFaddend \CSLRightInline{European Centre for Disease Prevention and Control, {``Threat {Assessment Brief}: {Implications} for the {EU}/{EEA} on the spread of the {SARS-CoV-2 Delta} ({B}.1.617.2) variant of concern,''} {ECDC}, {Stockholm}, Jun. 2021.Available: \url{https://www.ecdc.europa.eu/en/publications-data/threat-assessment-emergence-and-impact-sars-cov-2-delta-variant}}

\leavevmode\vadjust pre{\hypertarget{ref-europeancentrefordiseasepreventionandcontrolAssessmentFurtherSpread2022}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}38{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}43{]} }
\DIFaddend \CSLRightInline{European Centre for Disease Prevention and Control, {``Assessment of the further spread and potential impact of the {SARS-CoV-2 Omicron} variant of concern in the {EU}/{EEA}, 19th update,''} Jan. 27, 2022. \url{https://www.ecdc.europa.eu/en/publications-data/covid-19-omicron-risk-assessment-further-emergence-and-potential-impact}}

\leavevmode\vadjust pre{\hypertarget{ref-europeancentrefordiseasepreventionandcontrolOverviewImplementationCOVID192021}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}39{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}44{]} }
\DIFaddend \CSLRightInline{European Centre for Disease Prevention and Control, {``Overview of the implementation of {COVID-19} vaccination strategies and deployment plans in the {EU}/{EEA},''} {ECDC}, {Stockholm}, Nov. 2021.Available: \url{https://www.ecdc.europa.eu/en/publications-data/overview-implementation-covid-19-vaccination-strategies-and-deployment-plans}}

\leavevmode\vadjust pre{\hypertarget{ref-castroTurningPointEnd2020}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}40{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}45{]} }
\DIFaddend \CSLRightInline{M. Castro, S. Ares, J. A. Cuesta, and S. Manrubia, {``The turning point and end of an expanding epidemic cannot be precisely forecast,''} \emph{Proceedings of the National Academy of Sciences}, vol. 117, no. 42, pp. 26190--26196, Oct. 2020, doi: \href{https://doi.org/10.1073/pnas.2007868117}{10.1073/pnas.2007868117}.}

\leavevmode\vadjust pre{\hypertarget{ref-friedmanPredictivePerformanceInternational2021}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}41{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}46{]} }
\DIFaddend \CSLRightInline{J. Friedman \emph{et al.}, {``Predictive performance of international {COVID-19} mortality forecasting models,''} \emph{Nat Commun}, vol. 12, no. 1, 1, p. 2609, May 2021, doi: \href{https://doi.org/10.1038/s41467-021-22457-w}{10.1038/s41467-021-22457-w}.}

\leavevmode\vadjust pre{\hypertarget{ref-aleneSerialIntervalIncubation2021}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}42{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}47{]} }
\DIFaddend \CSLRightInline{M. Alene, L. Yismaw, M. A. Assemie, D. B. Ketema, W. Gietaneh, and T. Y. Birhan, {``Serial interval and incubation period of {COVID-19}: A systematic review and meta-analysis,''} \emph{BMC Infectious Diseases}, vol. 21, no. 1, p. 257, Mar. 2021, doi: \href{https://doi.org/10.1186/s12879-021-05950-x}{10.1186/s12879-021-05950-x}.}

\leavevmode\vadjust pre{\hypertarget{ref-jinLagDailyReported2021}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}43{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}48{]} }
\DIFaddend \CSLRightInline{R. Jin, {``The lag between daily reported {Covid-19} cases and deaths and its relationship to age,''} \emph{J Public Health Res}, vol. 10, no. 3, p. 2049, Mar. 2021, doi: \href{https://doi.org/10.4081/jphr.2021.2049}{10.4081/jphr.2021.2049}.}

\leavevmode\vadjust pre{\hypertarget{ref-catalaRobustEstimationDiagnostic2021}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}44{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}49{]} }
\DIFaddend \CSLRightInline{M. Català \emph{et al.}, {``Robust estimation of diagnostic rate and real incidence of {COVID-19} for {European} policymakers,''} \emph{PLOS ONE}, vol. 16, no. 1, p. e0243701, Jan. 2021, doi: \href{https://doi.org/10.1371/journal.pone.0243701}{10.1371/journal.pone.0243701}.}

\leavevmode\vadjust pre{\hypertarget{ref-brooksComparingEnsembleApproaches2020}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}45{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}50{]} }
\DIFaddend \CSLRightInline{L. Brooks, {``Comparing ensemble approaches for short-term probabilistic {COVID-19} forecasts in the {U}.{S}.''} 2020. \url{https://forecasters.org/blog/2020/10/28/comparing-ensemble-approaches-for-short-term-probabilistic-covid-19-forecasts-in-the-u-s/} (accessed Jul. 15, 2021).}

\leavevmode\vadjust pre{\DIFdelbegin %DIFDELCMD < \hypertarget{ref-bracherNationalSubnationalShortterm2021}{}%%%
\DIFdelend \DIFaddbegin \hypertarget{ref-dieboldComparingPredictiveAccuracy1995}{}\DIFaddend }%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}46{]} }
%DIFDELCMD < \CSLRightInline{J. Bracher \emph{et al.}, {``National and subnational short-term forecasting of {COVID-19} in {Germany} and {Poland}, early 2021,''} p. 2021.11.05.21265810, Nov. 2021, doi: \href{https://doi.org/10.1101/2021.11.05.21265810}{10.1101/2021.11.05.21265810}.}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}51{]} }
\CSLRightInline{F. X. Diebold and R. S. Mariano, {``Comparing {Predictive Accuracy},''} \emph{Journal of Business \& Economic Statistics}, vol. 13, no. 3, pp. 253--263, Jul. 1995, doi: \href{https://doi.org/10.1080/07350015.1995.10524599}{10.1080/07350015.1995.10524599}.}
\DIFaddend 

\leavevmode\vadjust pre{\DIFdelbegin %DIFDELCMD < \hypertarget{ref-aguasModellingCOVID19Pandemic2020}{}%%%
\DIFdelend \DIFaddbegin \hypertarget{ref-bracherNationalSubnationalShortterm2021}{}\DIFaddend }%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}47{]} }
%DIFDELCMD < \CSLRightInline{R. Aguas \emph{et al.}, {``Modelling the {COVID-19} pandemic in context: An international participatory approach,''} \emph{BMJ Global Health}, vol. 5, no. 12, p. e003126, Dec. 2020, doi: \href{https://doi.org/10.1136/bmjgh-2020-003126}{10.1136/bmjgh-2020-003126}.}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}52{]} }
\CSLRightInline{J. Bracher \emph{et al.}, {``National and subnational short-term forecasting of {COVID-19} in {Germany} and {Poland}, early 2021,''} p. 2021.11.05.21265810, Nov. 2021, doi: \href{https://doi.org/10.1101/2021.11.05.21265810}{10.1101/2021.11.05.21265810}.}
\DIFaddend 

\leavevmode\vadjust pre{\DIFdelbegin %DIFDELCMD < \hypertarget{ref-adibParticipatoryModellingApproach2021}{}%%%
\DIFdelend \DIFaddbegin \hypertarget{ref-europeancentrefordiseasepreventionandcontrolWeeklyThreatsReports}{}\DIFaddend }%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}48{]} }
%DIFDELCMD < \CSLRightInline{K. Adib \emph{et al.}, {``A participatory modelling approach for investigating the spread of {COVID-19} in countries of the {Eastern Mediterranean Region} to support public health decision-making,''} \emph{BMJ Global Health}, vol. 6, no. 3, p. e005207, Mar. 2021, doi: \href{https://doi.org/10.1136/bmjgh-2021-005207}{10.1136/bmjgh-2021-005207}.}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}53{]} }
\CSLRightInline{European Centre for Disease Prevention and Control, {``Weekly threats reports ({CDTR}),''} 2022. \url{https://www.ecdc.europa.eu/en/publications-and-data/monitoring/weekly-threats-reports}}
\DIFaddend 

\leavevmode\vadjust pre{\DIFdelbegin %DIFDELCMD < \hypertarget{ref-agostoMonitoringCOVID19Contagion2021}{}}%%%
%DIF < 
%DIFDELCMD < \CSLLeftMargin{{[}49{]} }
%DIFDELCMD < \CSLRightInline{A. Agosto, A. Campmas, P. Giudici, and A. Renda, {``Monitoring {COVID-19} contagion growth,''} \emph{Statistics in Medicine}, vol. 40, no. 18, pp. 4150--4160, 2021, doi: \href{https://doi.org/10.1002/sim.9020}{10.1002/sim.9020}.}
%DIFDELCMD < 

%DIFDELCMD < \leavevmode\vadjust %%%
\DIFdel{pre}%DIFDELCMD < {%%%
\DIFdelend \hypertarget{ref-borcheringModelingFutureCOVID192021}{}}%
\DIFdelbegin %DIFDELCMD < \CSLLeftMargin{{[}50{]} }
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \CSLLeftMargin{{[}54{]} }
\DIFaddend \CSLRightInline{R. K. Borchering, {``Modeling of {Future COVID-19 Cases}, {Hospitalizations}, and {Deaths}, by {Vaccination Rates} and {Nonpharmaceutical Intervention Scenarios} --- {United States}, {April}--{September} 2021,''} \emph{MMWR Morb Mortal Wkly Rep}, vol. 70, 2021, doi: \href{https://doi.org/10.15585/mmwr.mm7019e3}{10.15585/mmwr.mm7019e3}.}

\end{CSLReferences}

\newpage

\end{document}
